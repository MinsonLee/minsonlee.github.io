---
layout: post
title: "案例-Shell-文本处理：人人网访问记录分析"
date: 2020-08-02
tag: Shell
---

## 背景
千橡的人人网每天都会有数以亿计的访问者，每个访问者的访问行为在千橡的服务器中都会留下访问记录。访问记录里有许多信息，其中包含两个字段： 访问者的IP、访问者的用户id。例如， 格式是这样的：
```sh
>>> cat record.txt
10:20 202.114.112.5 32123453
10:21 213.89.113.5 34234234
10:22 202.114.112.5 32123453
10:23 213.89.113.5 34234234
10:24 202.114.112.5 32123453
```

每条记录分为 3 个字段，第一个字段是用户的访问时间，第二个字段是用户的访问 IP，第 3 个字段是用户的id，中间以空格隔开。这样的记录有什么用呢？ 千橡的工程师每天晚上都会分析这些用户数据：
1. 分析哪些 IP 的访问异常，例如出现短时间内大量访问的情况（可能是用机器人爬网页的结果）；
2. 分析哪些用户为活跃用户；
3. 分析哪些用户的账户存在异常（例如瞬间换另一个 IP 登录).

## 异常 IP 分析

> 异常 IP：同一分钟内，同一 IP 同 一 id 出现大量访问，则认为该 IP 为异常 IP

### 提取 IP 与 id  字段

```shell
$ cut -d " "  -f 2,3 record.txt
```
- `-d` 选项指定分割符为空格
- `-f` 选项取出指定列(列索引从1开始计算)

### 统计 IP 访问次数
>  统计第一纬度为 IP，因此以 IP 为排序索引，并根据此结果统计重复 IP 且重复 id 的次数

先根据 IP 进行排序
```shell
$ cut -d " " -f 2,3 record.txt | sort 

202.114.112.5 32123453
202.114.112.5 32123453
202.114.112.5 32123453
213.89.113.5 34234234
213.89.113.5 34234234
```

根据排序好的结果进行统计
```shell
$ cut -d " " -f 2,3 record.txt | sort | uniq -c

       3 202.114.112.5 32123453
       2 213.89.113.5 34234234
```
- `- c` 在输出行前加上重复次数

### 根据次数倒序排序
```shell
$ cut -d " " -f 2,3 record.txt | sort | uniq -c | sort -n -r

       3 202.114.112.5 32123453
       2 213.89.113.5 34234234
```
- `-n` 优先将结果当作数字进行排序，避免根据倒序排序时出现 100 在 2 后面的情况（默认：`sort`是将结果当作字符串进行排序的）
`-r`  倒序排序

### 取前 100 异常 IP
```shell
$ cut -d " " -f 2,3 record.txt | sort | uniq -c | sort -n -r | head -n 100

       3 202.114.112.5 32123453
       2 213.89.113.5 34234234
```
- `-n` 指定显示行数

## 活跃用户分析


## 异常用户分析